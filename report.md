## Разработка метода Entity Linking 

### Постановка задачи

В рамках практической работы, требовалось реализовать метод обнаружения ключевых сущностей в вопросительных предложениях
на русском языке и связать их с определением в Wikidata, если таковое имеется.

На вход подается некоторое вопросительное предложение. На выходе ожидается множество идентификаторов сущностей,
представленных в вопросе, в формате Wikidata.

Тестирование проводилось на сотне размеченных автором вопросов.

#### Метрики качества
В качестве метрик качества используется число верно и не верно найденных идентификаторов на размеченном корпусе и
микро-усреднённые, посчитанные из них.

### Общая модель решения

Решение будет построено на основе Named Entity Recognition и данных о синтаксической структуре предложения
(в частности, на основе данных о зависимостях между словами). 

Используя эти данные, мы построим запросы к полнотекстовому индексу Wikipedia, откуда перейдём в WikiData.

#### Named Entity Recognition

В предложенном решении используется BERT-based NER модель от проекта DeepPavlov
([документация](http://docs.deeppavlov.ai/en/master/features/models/ner.html)).
В частности, данная модель позволяет находить в тексте токены, относящиеся к
конкретной персоне (А.С. Пушкин) или организации, а они, в свою очередь, в большинстве случаев важны для вопроса.

Заметим, что NER у DeepPavlov проводит также и токенизацию. Токены, полученные от NER, будут использоваться и далее.

#### Syntactic Parsing

Токены, полученные от NER, передаются в 
[JointModel](http://docs.deeppavlov.ai/en/master/features/models/syntaxparser.html#joint-model-usage). 
Данная модель производит POS Tagging, Syntactic Parsing и лемматизацию. 

В результате для каждого токена мы имеем данные о его POS теге, положении в дереве зависимостей и лемму.

Далее, мы сначала берём сущности, отмеченные NER, и собираем запросы для них. Для каждой из сущностей создается
отдельный запрос:
* В запрос добавляется сама сущность &mdash; все слова в форме лемм;
* В запрос добавляются элементы предложения связанные с данной сущностей в синтаксическом дереве отношением
модификации (amod, nmod) тоже в виде лемм
* Все леммы конкатенируются в порядке, в котором они встречались в предложении

Для существительных (POS tag: NOUN, PROPN), которые не попали ни в один из запросов, создаются свои запросы. Однако
для них не производится сбор зависимостей (так как в процессе тестирования было показано, что эти зависимости для
абстрактных существительных только ухудшают качество поиска).

#### Поиск

Каждый запрос выполняется через API Wikipedia для полнотекстового поиска. Среди результирующих страниц выбирается
первая, после чего для неё производится поиск сопоставленного идентификатора в WikiData (через API Wikipedia).

Заметим, что в первом варианте используются Google Search с фильтрацией результатов по `site:ru.wikipedia.org`,
однако, несмотря на лучшие результаты, данный подход на масштабируется, из-за крайне агрессивных rate limit
сервиса Google Search.

### Результаты

В итоге на 100 вопросов полученное решение верно сопоставляет 125 сущности, 143 сущностей выделяются не верно или
сопоставляются не верно. Общее число ожидаемых сущностей 214.

Таком образом точно найдено 58.4% сущностей. При этом в среднем найдено 2.68 сущности на вопрос,
когда в действительности их 2.14.

Используя микро усредненные метрики:
* Полнота 125/214 = 58.4%
* Точность 125/(125+143) = 46.6%

#### Оценка решения

Предложенное решение хорошо производит поиск сущностей выявляемых NER и абстрактных сущностей
(типа "повесть" в вопросе "Какая повесть есть у А.С. Пушкина?")

Тем не менее, решение не способно выявлять сущности находящиеся в зависимости (к примеру, в вопросе "Где Гарри
впервые поцеловал Джинни?" ясно, что имена Гарри и Джинни вместе встречаются только в серии книг о Гарри Поттере,
однако решение это не учитывает.)

Кроме того, текущий подход не ранжирует существительные и не может отбросить некоторое существительное,
посчитав что оно не важно для вопроса. Вероятно, решение этой проблемы позволит сократить число обнаруженных
сущностей на вопрос.

### Другие подходы

В рамках работы было перепробовано некоторое число подходов, от которых пришлось отказаться.

#### Использование исключительно NER

Одной из идей было использовать исключительно сущности, полученные из NER и не искать сопоставления для существительных,
если NER их не выделил.
 
Однако NER обладает крайне узким классом категорий и не выявляет большое число слов, важных для
вопроса. К примеру, "Какая повесть есть у А.С. Пушкина?" &mdash; здесь NER выделит только "A.C. Пушкина", хотя крайне
важно и то, что спрашивается про повесть. Поэтому, поиск производится для всех существительных.

Конечно, в идеале стоило бы производить поиск исключительно для "абстрактных" существительных, однако каким образом
отделять важные существительные (абстрактные, описывающие концепции) от не важных &mdash; не ясно. Разве что словарями.

#### Использование контекста во всех случаях

Другой идеей было использовать контекст слова (полученный по синтаксическому дереву) не только для NER, но и вообще во
всех случаях. 

Однако в таком случае выделялись слишком конкретные группы слов. К примеру, "автор английского гимна" не разделялся на
две сущности "автор" и "английский гимн", а оставался одной. Это приводило к существенной деградации точности поиска
по полнотекстовому индексу. 

### Нереализованные идеи

Рассмотрим некоторые из идей, которые не были реализованы, но теоретически могли бы улучшить результат.

#### SPARQL пост-фильтрация

На данный момент в запросах никак не используется информация о категории сущности, выделенной NER. Вообще говоря,
можно было бы получить несколько WikiData идентификаторов и находить среди них только те, что относятся к искомому
типу сущностей.

#### Использование глаголов

В решении никак не используются глаголы из контекста. К примеру, для вопроса "Кто пленил князя Игоря?" строится
запрос "князь Игорь", который не находит правильного князя Игоря (их было несколько в русской истории). При этом
запрос "пленить князь Игорь" уже находит верного князя Игоря, так как в его статье на Wikipedia есть упоминание
о пленении.

Тем не менее, глаголы не используются в текущем решении, так как в большинстве случаев они не привносят
новые данные о конкретной сущности, а скорее связаны с вопросом.

### Использование связей

В решении никак не используются связи между сущностями. Тем не менее, их можно выявить в вопросе и можно произвести
поиск в базе знаний. 

К примеру, для вопроса "Где впервые Гарри поцеловал Джинни?" Можно было бы найти все сущности,
связанные одновременно с сущностями найденными для запроса "Гарри" и для запроса "Джинни" и минимизировать расстояние
в этой тройке. Вероятнее всего, тройка в базе знаний оказалась бы "Джинни Уизли", "Гарри Поттер", "Гарри Поттер (книга)".

Более того, найдя вторую такую тройку, мы могли бы с полной уверенностью утверждать, что вопрос неоднозначен.

Предположительно, такой графовый подход позволит существенно увеличить точность.

### Выводы

По итогам проделанной работы:
* Удалось получить приемлемую точность, используя достаточно простое решение, основанное на доступных фреймворках и API
* Имеются возможности для улучшения полученного решения в нескольких аспектах
    * В частности, использование связей должно позволить существенно улучшить результат
* Полученный подход хорошо масштабируется и может использоваться при обработке больших датасетов, при условии
наличия локального полнотекстового индекса Wikipedia.


