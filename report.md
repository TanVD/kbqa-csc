## Разработка метода Knowledge Based Question Answering

### Постановка задачи

В рамках практической работы, требовалось реализовать метод трансляции вопроса на русском языке в SPARQL запрос
к базе знаний WikiData. При этом гарантировалось, что в запросе могут присутствовать лишь отношений из списка
`['P17', 'P50', 'P36', 'P276', 'P170'].`

Эти отношения соответственно:
* `P17` -- страна сущности (`COUNTRY`)
* `P50` -- основной автор сущности (`AUTHOR`)
* `P36` -- главный город (областной центр, столица) сущности (`CAPITAL`)
* `P276` -- местонахождение сущности (`LOCATION`)
* `P170` -- создатель (творец) сущности (`CREATOR`)

Важно отметить, что все эти отношения напрямую связываются с сущностью вопроса. То есть, если запрашивается
столица, то как правило в вопросе будет указано конкретная территориальная единица, относительно которой столица
запрашивается.

Тестирование проводилось на сотне вопросов, для которых автор вручную сопоставил ответы в базе знаний.

### Метрики качества

В качестве метрики использовалось общее число успешно построенных SPARQL запросов и общее число запросов, нашедших
верный ответ. 

В качестве метрики не использовалось сопоставлением с эталонным запросом (очевидно, для большого числа вопросов существует
более одного способа создать SPARQL запрос), однако требовалось, чтобы запрос не был тривиальным (содержал поиск по базе знаний)


### Общая модель решения

Решение было построено на основе предыдущего решения для Entity Linking и отдельно реализованного классификатора для
определения используемого в данном вопросе отношения.

### Entity Linking

В предыдущей работе был предложен метод Entity Linking, основанный на полнотекстовом поиске, NER и Syntactic Parsing. 
В данной работе метод используется, для того чтобы вычленить ключевые сущности, относительно которых и задается вопрос.

Несмотря на хорошие результаты (полнота 58.4%) метод потребовалось частично переработать. Во-первых, так как все
вопросы задаются относительного одного конкретного элемента ("Кому принадлежат слова **"И ты, Брут?"**") метод был 
переработан таким образом, чтобы возвращать исключительно ключевые сущности. Работает это следующим образом:
* сначала извлекаются фразы в кавычках (`QUOTED`);
* если таковых нет, извлекаются сущности найденные NER (`NER`);
* если таковых нет, извлекаются собственные существительные (`NNP`);
* если таковых нет, извлекаются несобственные существительные (`NN`).

Фактически, это означает что алгоритм, извлечет наиболее специфичную сущность -- вероятнее всего название или цитату.

К примеру, из вопроса `Кому принадлежат слова "И ты, Брут?"` будет извлечено `"И ты, Брут?"`. А из вопроса `Какой город
является столицей Испании` будет извлечено `Испания`.
 
Учитывая специфику вопросов (все они напрямую связываются с сущностью) нам как раз и нужна одна сущность.

### Классификация запроса

Для того, чтобы составить SPARQL запрос, нам потребуется сопоставить вопрос и тип отношения, которое запрашивается.

Однако так как размеченных данных довольно мало, обучать качественный классификатор может быть довольно сложно или же
даже невозможно. 

Вместо этого, было решено использовать подход на основе правил, полученных путём анализа вопросов. Каждый вопрос
представляется как множество лемм, после чего набор лемм соответствующих тому или иному отношению пересекается с
набором лемм вопроса.

Множество лемм отношений довольно просты. К примеру, для `AUTHOR` используется `{"кто", "автор"}`, 
`{"кто", "написал"}` и аналогичные наборы.

При этом заметим, что классификатор может выдать более одного отношений, просто указав порядок в котором стоит их искать.
К примеру, для `{"кто", "автор"}` он выдаст `[AUTHOR, CREATOR]`, то есть сначала нужно поискать по отношению `P50`, а
если найти не удастся, то по `P170`.

Итоговый классификатор даёт всего лишь `3%` не классифицированных вопросов. 

### Поиск

Используя полученные из вопроса ключевые сущности и массив вероятных отношений, остаётся создать запрос к WikiData.

Отношений берутся в порядке нахождения в массиве, то есть в порядке их вероятности для данного вопроса. Далее,
все сущности объединяются через `.`. В большинстве случае сущность будет только одна.

К примеру, для вопроса `Кому принадлежат слова "И ты, Брут?"` будет построен запрос
`SELECT ?answer WHERE { wd:Q617371 wdt:P50 ?answer }` и менее вероятный
`SELECT ?answer WHERE { wd:Q617371 wdt:P170 ?answer }"`.

Запросы выполняются через WikiData API пока первый не вернёт результат.

### Результаты
В итоге на 100 вопросов полученное решение получает верные ответы на 63 вопроса, а всего строит 67 SPARQL запросов.
(если брать наиболее вероятные).

Заметим, что данная статистика подсчитана с помощью предложенного метода поиска -- с перебором всех запросов до 
первой сущности.

#### Оценка решения

Предложенное решение показало хорошие результаты на имеющемся корпусе данных. Однако вполне вероятно
что классификатор покажет худшие результаты на данных не из корпуса, так как основан на правилах, выведенных
из зависимостей корпуса вручную.

Отдельно отметим, что решение расширяемо на другие отношения -- фактически достаточно обновить классификатор и оно
сможет отвечать и на новые вопросы. 

### Анализ

Опишем процесс разработки данного решения, с целью более точно проанализировать результаты.

#### Первый этап: один тип отношений, нет QUOTED

Первый вариант включал в себя поиск ключевой сущности по цепочке `NER -> NNP -> NN`. Как только находилась сущность,
поиск прекращался. На первом этап не использовались слова в кавычках.

Кроме того, на первом этапе классификатор выдавал только один тип отношений. Довольно быстро стало понятно, что
это не всегда удобно -- вопросы довольно близки и часто нельзя точно сказать будет ли найден запрос
через отношение `AUTHOR` или `CREATOR`

Результаты на первом этапе были следующими:
* 28 из 100 запросов составлено
* 25 вопросов получили корректные ответы

### Второй этап: union отношений, нет QUOTED

Во втором варианте были изменен классификатор -- теперь он выдавал несколько типов отношений соединённых через `|`. 

Главной проблемой такого подхода оказалось то, что многие сущности содержали несколько отношений. Соответственно,
запрос для сущности `Президентский полк` отношений `LOCATION` или `COUNTRY` приводил к ответу `RUSSIA` и `KREMLIN`, а
не только `KREMLIN` (очевидно, являющийся ответом на вопрос `Где расквартирован российский Президентский полк?`)

Результаты на втором этапе были следующими:
* 47 из 100 запросов составлено
* 35 вопросов получили корректные ответы

Кроме того, тут же стало понятно что из запросов нужно отфильтровывать слова, явно относящиеся к отношению (`страна`,
`город` и т.д.)

### Третий этап: перебор отношений, нет QUOTED

В третьем варианте снова был изменён классификатор -- теперь он выдавал массив отношений в порядке их вероятности.

Такой подход избавлял от проблемы, описанной в примере с `Президентским полком` и при этом сохранял полноту.

Результаты на третьем этапе были следующими:
* 47 из 100 запросов составлено
* 42 вопроса получили корректные ответы

### Четвёртый этап: перебор отношений, использование QUOTED

После внимательного анализа стало понятно, что многие названия произведений и цитаты не вычленяются полностью с помощью
NER. Вместо этого извлекаются лишь некоторые конкретные слова. Была изменена цепочка поиска ключевой сущности на
`QUOTED -> NER -> NNP -> NN`, то есть сначала извлекались фразы в кавычках.

Вкупе с другими оптимизациями итоговый результат получился следующим:
* 67 из 100 запросов составлено
* 63 вопроса получили корректные ответы

### Выводы

По итогам проделанной работы:

* Удалось получить достаточно высокую точность, переиспользовав предложенный ранее метод и учтя ограничения задачи
* Предложено улучшение для ранее предложенного метода Entity Linking для поиска ключевых сущностей
* Показана возможность обобщения метода на другие типы вопросов
